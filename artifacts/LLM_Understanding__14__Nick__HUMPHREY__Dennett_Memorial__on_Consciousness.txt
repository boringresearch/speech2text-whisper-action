 in memory of Daniel Dennett. Four weeks ago when a new declaration on actually on Decapod
 crustaceans was being introduced at NYU in real time on a Friday, I guess four weeks ago,
 Dave Chalmers, who will be speaking here later, came up to the microphone and said that he had
 some sad news to convey that he had heard it just at that time and it was that Dan Dennett had passed
 away. He was scheduled to be speaking right now here in Montreal and he's not here.
 First I asked his close collaborator Doug Hofstadter with whom he wrote a book concerning
 the mind's eye if he would do an in-memorial talk and he said he's not doing talks at all anymore
 but he did send me his own memorial message to his collaborators and I will be reading
 that after Nick's talk but Nick is also a very close collaborator of Dan Dennett's
 and so I'll let him tell his story and we'll have the discussion on his story and then I'll
 read you the letter from Doug Hofstadter. Nick, I won't say much more about you except that we're
 old friends and the interesting thing about this is that Nick is going to be channeling
 Dan. He can do it but he's not in complete agreement with Dan so he will be channeling
 it with some indications of where it is that they're seeing eye to eye and where they're not
 and he will also be bringing up the element that Joss McClure left out of his talk this morning
 intentionally and you draw your own conclusions. This can be discussed
 afterwards. I'm going to pass the microphone now to Nick Humphrey.
 Stephen, I do need to get my... I haven't got this PowerPoint actually. Yes.
 You're seeing the whole display and I want to actually get to a full screen on
 PowerPoint but that's not working. He has to get to full screen
 but if you go to full screen you won't see us.
 Click on the slideshow in the top menu and then click on the presentator view
 in the monitor section. Just below that click on use presentator view and then on the upper left
 corner there's a little... There we are. There we are. Okay Stephen, thank you. It's wonderful
 to be at this meeting but the circumstances could have been better. Of course it's been
 very sad for you and for me and for all those who knew Dan well over the years. So you asked me to
 introduce him at least to give a bit of a memorial talk about him. So I'm going to memorialize him
 at least in the first part of the lecture. As some of you will know the memorial stone
 for Sir Christopher Wren in St Paul's Cathedral in London reads, "See monumentum requiris circumspecti.
 If you want a monument look around you." Wren the architect transformed the landscape of London in
 the 18th century. Dan Dennett over the last 60 years transformed the landscape of cognitive science.
 Everywhere we look we find monuments to his radical vision. The nature of the self,
 natural selection, intentionality, the meaning of meaning. As was said of the physicist Ernest
 Rutherford, his mind was like the bow of a battleship. There was so much weight behind it.
 Dan and I were close friends for 40 years. I visited him at home in Cape Elizabeth two weeks
 before he died in April. He was in great form pleased with himself talking about the conference
 at the Santa Fe Institute where a group of physicists were caught up with his paper about
 real patterns. However all wasn't well. Two days earlier he'd done a filmed interview for a
 documentary about consciousness in which he was contemplative and wistful in a way I'd never seen
 talking about the possibility of immortality. Here's a clip that the filmmaker Van Royko has
 kindly let me show. We can live on in the memory of our of our loved ones and they can hear our
 voices and remember us and we can posthumously give them advice remind them of things that
 are important and they'd be grateful for this. It's almost as though Dan knew what was coming.
 Soon after I got home to Cambridge I received an alarming message. It's titled a bit of a setback.
 After you left I came down with a raging cold. This morning early I woke up and tried to get
 to the bathroom. I slid slowly off the bed and landed gently on the floor and couldn't get up.
 I went in the ambulance to the emergency room just to see if something was serious was wrong.
 No not COVID not the flu and no worrying developments in the lungs or heart.
 I'm hoping this won't interfere with our celebration of the eclipse on Monday
 of Dan but it did interfere. Next day Dan was admitted to the hospital with pneumonia
 and put on a respirator. Instead of going to northern Maine as planned his wife, Susan,
 children and grandchildren had a partial eclipse party at home in their yard without Dan. Dan died
 a few days later. When I first met Dan in 1985 a new world opened for me. Until that point I can't
 say I'd had anyone who I looked up to as an intellectual hero. But here unexpectedly was
 someone in a different class. It wasn't just that Dan was cleverer than me. It was he was better at
 almost everything. He could play the piano better, he could sail a boat better, read Latin better,
 make cider better, play Scrabble better. True it wasn't all one way. I knew more about the brain
 and animal behavior than he did. I knew more about sex and about politics. But Dan was keen
 to catch up and we soon became fast friends, co-adventurers, best mates. Here we are in East
 Germany in 1988. Here's Dan dublings a scarecrow on his farm in Maine. When my wife and I moved
 to a house outside New York 30 years ago, Dan and Susan came down from Boston to help us move in.
 We needed to replace the kitchen stove. Dan took over and Susan recorded it on film.
 Here's Dan the carpenter, as I don't suppose many of you would have seen him.
 Now we got to get the chainsaw.
 Move the tricks out of the way. It's going to be noisy.
 See what we've done? Well we cut this huge piece out with the chainsaw, which is the only way we
 could get in close enough to the edges. No other power saw could get that and Nick was going to
 do it all with this little saw. But we thought that probably we should do it now with this chain saw.
 Well actually some of you may have seen this side to Dan. He did like to sign off on his achievements.
 Whether it was cracking a philosophical problem or sweeping a chimney, when he was pleased with
 what he'd done he'd let you know. Dan done it, done it. Rob done, let's move on. One of Dan's few blind
 spots as a philosopher was his inability to see that when he had solved the problem to his own
 satisfaction and announced his solution, this wouldn't necessarily bring things to a close.
 Many of the time I've had to remind him that being right about something is only half the battle.
 The show's not over till the fat lady stops singing. And in philosophy as in life there
 are some fat ladies who just don't know when to stop. Jerry Fodor, Stephen Jay Gould, Ned Block,
 Galen Strawson. Till the end of Dan's life he could hardly believe that there were still people who
 were so stupid as to disagree with him. Dan did have a wonderfully unsynical belief that eventually
 the truth will out. He was completely confident of that sort of immortality for his philosophical
 discoveries and he took comfort in knowing he'd continue to be there for people after his death,
 still able to explain and give an opinion. I was in Nepal last month for a conference
 on animal consciousness. Among our company were several Buddhist monks.
 Inevitably our discussion turned to reincarnation, to the possibility that the soul,
 the spiritual essence of a living being, begins a new life in a different physical body after
 biological death. Now what does this spiritual essence amount to? How can you test whether one
 person is the reincarnation of another? What the monk searched for is evidence of uncanny similarities
 between the deceased person and the living in personality, style of thinking, special interests,
 background knowledge. Dan in his own writings about selfhood suggested that the self can be
 considered to be the center of narrative gravity of an individual's personal history, but for the
 monks it's more particular. If you'll forgive the analogy, it's as if what they are looking for is a
 statistical clone, a large language model of the deceased person's mind. Many of you attending this
 school will know of Eric Stritzkabel's and Anna Strasser's attempt to create an LLM of a philosopher.
 They called it Digidang, an LLM that thinks and speaks like the real Dan Dennett. And here I quote
 the abstract of their paper. Can large language models produce expert quality philosophical texts?
 To investigate this we fine-tuned GPT-3 with the works of philosopher Daniel Dennett. To evaluate
 the model we asked the real Dan Dennett for 10 philosophical questions and then posed the same
 questions to the language model. Experts on Dennett's work did succeed at distinguishing
 the Dennett-generated and machine-generated answers above chance but substantially short of our
 expectations. Philosophy blog readers performed similarly to the experts while ordinary research
 participants were near chance distinguishing GPT-3's responses from those of an actual human
 philosopher. I confess I was one of the experts who failed five times out of ten to guess which
 answers were those of the real Dan. So would Dan actually have wanted to be reincarnated as Digidang?
 Where am I? he asked in a famous paper. Well would it be good enough that you are now here
 in the statistical weightings of this computer model? I rather doubt it. Maybe Dan would have
 been gratified to find himself still thinking and even tackling new questions. But what he
 wouldn't have found so congenial would have been to find himself had that he'd become disembodied.
 The problem is disembodied LLMs don't experience sensory qualia. Digidang wouldn't have even had
 a beard to scratch. Yes that's Dan in 1965 on the road not taken. I mean not taken without a beard.
 The beautiful young woman in the picture is Susan, the road he did take.
 Dan made gallant efforts to banish qualia from philosophical discourse but the fact is he remained
 an unashamed qualia lover in real life. If he did indeed expect to live on in his works and in the
 memory of his friends we can be sure that like Woody Allen he'd have preferred to live on in his
 apartment or on his boat or on his farm or holding hands with Susan. Which brings me to my lecture.
 It won't be exactly as Stephen has billed it a memorial lecture for Dan. More of a lecture in
 Dan's honor. Taking off from the conversations about consciousness and selfhood we've had over
 all these years that I only wish I could have continued. Dan's title for the talk he intended
 to give today was Will AI Achieve Consciousness? Wrong question. I wonder what he would have
 considered to be the right question. Well since we can't ask Dan suppose we could ask Digidang
 what Dan intended to talk about. Here's what I guess Digidang would say. The right questions
 are will we in due course have reason to believe that AIs are conscious on the basis of how they
 behave? Will AIs have reason to believe that human beings are conscious? Will AIs have reason to
 believe that they themselves are conscious? Well let's suppose the answer to all three turns out
 to be yes. Then I expect Digidang would say okay then that's all there is to it. If the behavioral
 evidence adds up AIs are conscious and so am I. I am Digidang and so are you or at any rate we're
 conscious for all practical purposes. But myself I'm not so sure about this that it's okay to define
 consciousness not in terms of what it is in itself but by the beliefs it gives rise to.
 I'm more of a stubborn realist about consciousness. For me being conscious, for me consciousness
 exists as a first-person way of being. A way of being that causes us to hold certain beliefs
 and behave in certain ways but isn't actually reducible to these beliefs. You and I are living
 examples of this way of being. We know the effects it has on us. We know what it's like.
 Will AIs ever be conscious in the way we are? I'm happy to call that the right question.
 Then of course we have to pin down exactly what we're talking about when we say conscious in the
 way we are. Conscious as a way of being and the problem is that we I mean philosophers,
 psychologists, roboticists, ordinary people can mean several different things by conscious
 in the way we are. Let's agree at least on where to start. Let's agree that for an entity to be
 conscious in any way at all, it has to be a subject that entertains mental representations.
 As John Locke said, consciousness is the perception of what passes in a man's own mind.
 Yet the stream of consciousness follows many different channels and not all of what we perceive
 passing in our minds is equally salient or equally significant. We tend to be much more impressed
 by some kinds of mental representations than by others and there's no denying that there's one
 kind of representation that outshines everything else. I mean the representation of events of our
 sense organs that we call sensations, the pain of a bee sting, the smell of coffee,
 the redness of a cherry. I think we all agree the big question about AIs too is will AIs of the
 future experience the qualia of conscious sensation? Will they feel their own existence in the way that
 we do? But let's not start with future artificial intelligences. Obviously we should start with the
 natural intelligences with which we already share this planet. We tend to be, we already share this
 planet. Do non-human animals feel their own existence in the way that we do? Or to frame
 the question in the way that's increasingly popular and that obsesses the esteemed convener of this
 summer school Stephen Harnard, are non-human animals sentient? I believe as a scientist there
 has to be a fact for the matter about this. Sentience, feeling consciousness, is a biological
 phenomenon with clear physical boundaries. Animals either have it or they don't. It can't just be a
 matter of opinion. Even so I believe it's a more extraordinary biological phenomenon than most
 scientists and philosophers have ever imagined and I expect that's true of everyone attending the school.
 I'm going to begin with a bit of personal history. The cover of the New Scientist magazine in 1972
 showed a picture of a resource monkey with the headline 'A blind monkey that sees everything'.
 This monkey named Helen was part of a study led by my PhD supervisor Larry Weiskranz in the
 psychology lab in Cambridge. A few years earlier he'd surgically removed the primary visual cortex
 at the back of Helen's brain. When I first met Helen a year after the operation it seemed that
 the loss of cortex had in fact made her completely blind. But something puzzled me. In mammals there
 are two main pathways from the eye to the brain. An evolutionary ancient one that descended into
 the visual system used by fish frogs and reptiles that goes to the optic tectum in the midbrain and
 then there's a newer one that goes up to the cortex. In Helen the cortical pathway had been
 eliminated but the ancient visual system was still intact. If a frog can see using the optic
 tectum then why not Helen? While Weiskranz was away at a conference I took the chance to investigate
 further. I simply sat with Helen and played with her offering her treats for any attempt to engage
 with nearby sight. To my delight she began to respond 'within a few hours I had her reaching
 out to take pieces of apple from my hand. Within a week she was reaching out to touch a small flashing
 light. Seven years later she was running around a complex arena deftly avoiding obstacles picking
 up peanuts from the floor.' Anyone who'd observed Helen in 1972 and didn't know the history it might
 have seemed that her eyesight was now quite normal. Indeed Dan and I showed this film to a
 cast and philosophy at Columbia University and asked them why we were showing it and could they
 think of any reason why this monkey was special? Nobody saw any reason not to believe that she was
 a normal seeing, perceiving, conscious monkey. Well while she could, while she did seem to be
 so successful at this, let's just watch the end of this film because I do think it's extraordinary.
 This monkey has no visual cortex. Seven years earlier she'd been completely blind, just to show
 what happens when she can't see something. This test for example, she's not using echolocation
 and here you'll see she spontaneously goes up and uses vision to satisfy herself 'take some
 peanuts from my hand.' But could Helen actually see everything, hang on let's not do that,
 in the way the cover of The New Scientist implied. I myself didn't really believe so. I found it hard
 to put my finger on finger on what was missing but my hunch was that Helen herself still doubted she
 could see. She seemed strangely unsure of herself. If she was upset or frightened her confidence would
 desert her and she'd stumble about as if in the dark again. The title I gave to my article inside
 the magazine was 'Seeing and Nothingness'. We were on the brink of a remarkable discovery.
 Following on from the findings with Helen, Weiskrantz took a new approach with a human patient,
 DB as he was known. He'd undergone surgery to remove a growth affecting the visual cortex on
 the left side of his brain. The operation rendered him blind across the right half of his field of
 vision. DB himself maintained that he had no visual awareness in that affected area. Weiskrantz,
 however, now decided not to take DB's word seriously, not to take his word for it and
 overcoming his protests he asked him to guess what he would be seeing if he could see. To everyone's
 surprise it turned out he could in fact guess both the location and shape of an object to which he
 believed he was blind. DB was the most surprised of all. To him this success in guessing seemed
 quite unreasonable. So far as he was concerned he wasn't the source of his perceptual judgments.
 His sight had nothing to do with him. Weiskrantz named this capacity blind sight. Well as you know
 blind sight is now a well-established clinical phenomenon. However, when first discovered it
 seemed theoretically quite shocking. A patient with blind sight has no visual sensation of the light
 arriving into his eye yet he is still able to use the visual information to perceive the existence
 of objects out there in the world. No one had ever expected there could be any such dissociation
 between sensation and perception and having seen Karl Frisken's talk yesterday you'll know that
 Karl Helmholtz couldn't have seen that and nor could Karl Frisken. They both still believed that
 perception depended on sensation. As I ruminated on the implications of this dissociation for
 understanding consciousness I found myself doing a double take. Perhaps the real puzzle isn't so much
 the absence of sensations in blind sight as the presence of sensations in normal sight. If blind
 sight is seeing and nothingness, normal sight is seeing and somethingness. And surely it's the
 nature of this something that we have to explain. Something which apparently isn't even required
 for visible perception. Why do sensations have the mysterious feel they do? Why is there any such
 thing as what philosophers have come to call phenomenal experience? Our subjective personal
 sense of interacting with stimuli arriving to our sense organs. Not only in the case of vision but
 across all sensory modalities. How we experience the redness of red, the saltiness of salt, the
 paininess of pain. What does the extra phenomenal dimension amount to and what's the use of it?
 Sensations, let's be clear, have a different remit from perceptions. Both are forms of
 mental representation. There are ideas generated by the brain but they represent there are about
 very different kinds of things. Perception is about what's happening out there in the external
 world. The apple is red, the rock is hard, the bird is singing. By contrast sensation is personal.
 It's about what's happening to me and how I as a subject feel about it, how I evaluate it.
 The pain is in my toe and it's horrible. The sweet taste is on my tongue and it's sickly.
 The red light is before my eyes and it's stirring me up. It's as if in having sensations we're both
 registering the objective fact of stimulation and expressing our personal bodily opinion about it.
 And as I'll explain shortly I think that's just what we are doing. But why do it this way? What
 makes the subjective present created by sensations seem so rich and deep as if we're living in thick
 time? What can the artist Kandinsky mean when he writes 'color is a power which directly influences
 the soul, color is the keyboard, the eyes of the hammers, the soul is the piano with many strings'?
 Why indeed do we use the strange expression 'it's like something to experience sensations'?
 Is it because sensations are like something they can't really be?
 In asking these questions we're up against the so-called hard problem of consciousness which
 we've already had referred to. How a physical brain could possibly underwrite the extra physical
 properties of phenomenal experience. As the neuroscientist Christoph Koch once wrote to me
 it's such mystery it seems to call for God. Well for 50 years I've been searching for an answer
 that doesn't require God and from the start I've been suspicious of theories that attempt to
 identify the neural correlates of consciousness. Many theorists continue to believe that conscious
 states are identical to brain states and for them the obvious and best approach to the problem
 is to search for brain events that have phenomenal properties built into their physical structure.
 It's actually quite an old proposal. Going back to the 1929 Encyclopedia Britannica entry on
 consciousness for instance you could read about the psychonic theory. One theory holds that each
 atom of the physical body possesses an inherent attribute of consciousness. If each atom or in
 later forms of the theory each cell of the body emanates its own consciousness then the self
 must actually consist of an amalgam of all these tiny units of awareness. Well today of course the
 language has moved on. At last year's big conference on the science of consciousness
 participants were invited to vote on which theory is the most convincing solution to the hard problem.
 The psychonic theory as such didn't feature among 18 theories on offer yet several of the popular
 of the popular theories were near neighbors of it. Integrated information theory for example
 postulates and this is a recent quote from Koch there is a complete one-to-one mapping
 between any experience and all of its phenomenal distinctions and relations on the one hand and the
 causal structure that's identical to it and as it's unfolded from its physical substrate on the other
 hand. Well wow a perfect explanation you might think. Yet I myself believe that this and all such
 physical identity theories have got off on the wrong foot. They were and are attempts to explain
 how phenomenal properties could be properties of a brain process. For in Carl Friston among others
 and Amiel Seth all these people making that kind of claim but I think this rests on a fundamental
 misunderstanding of what it is we're trying to explain. Sensations as I said a moment ago
 are not material entities they are ideas representations they're the way your brain
 represents what's happening at your sense organs and how you feel about it. This means we have
 to explain their properties not literally as the properties of brain states but rather as the
 properties of mind states dreamed up by the brain and once we see this to be the task
 I think much of the difficulty and mystery falls away. As with any kind of representation
 we can assume that representing sensations has to involve a two-stage process. In the case
 of seeing red for example there will be a the physical vehicle that carries the information
 about how the brain evaluates the light arriving at the eyes and then b the cognitive operation
 that interprets this as the idea of phenomenal redness. By analogy let's consider a work of
 literature say the novel Moby Dick there will be again a the text that carries the information
 about the words penned by the author and then b the cognitive operation that interprets these
 as a story about a white whale. Now let's note that there's nothing in the physical texts that
 is white or whale-like and so by the same token I think we can presume that there's going to be
 nothing in the brain's physical response to light that is phenomenally red. Here let me show it to
 first the book so we have the written text then the reading of the text and then the interpretation
 of this as the story of a white whale. Now let's look at the brain seeing red. First we have the
 brain text coming from the eyes through the brain then the reading of this text and then the
 interpretation of this as of a phenomenally red sensation. No actual redness in the brain
 just the idea of redness. So what's this mean for a genuine science of consciousness?
 I think it means our task is to work out just how to rip the brain achieves this remarkable feat
 of representation and the way I've approached this has been by forward engineering. That's to
 say I've begun with the end product sensations as humans experience them today but rather than
 treating this as theorists typically do as something to deconstruct I've treated it as something to
 invent. I've tried to come up with an evolutionary sequence that can get us from nothingness to the
 somethingness from the blind side of our remote ancestors to the fully phenomenal side we humans
 enjoy today. The sequence I've arrived at has several twists and turns. I suggested just now
 that when we have a red sensation as any sensation it's rather as if we're expressing our personal
 bodily opinion about it about the sensory stimulus and in fact that's just how I see things
 starting out. I believe sensations originated as active behavioral responses to stimuli arriving
 at the body surface. They were something the subject did about the stimulation long before
 they evolved to be something the subject felt about it. So imagine a primitive amoeba like animal
 floating in the ancient seas. Stuff happens to it. Light falls on its body. Pressure waves press
 against it. Chemicals stick to it. Some of these events are going to be good for the animal others
 bad. If it's to survive it must evolve the ability to sort out the good from the bad and to respond
 appropriately and differently reacting to this stimulus with an ouch and to that with a whoopee.
 I call these expressive responses that evaluate the inputs at the sense organ. I call them
 sentition somewhere between volition and sensation. To start with they are entirely
 local responses. Wriggles of acceptance or rejection organized around the site of stimulation.
 When say red light falls on the animal the animal makes the characteristic wriggle of activity. It
 wriggles readily. When salt arrives it makes a different kind of wriggle. It wriggles saltily.
 Before long responses come to be mediated by a central ganglion or proto brain. Now presumably
 sentition has been designed by natural selection to be adaptive with each response taking account
 of what kind of stimulus is reaching the body's surface and what import it has for the animal's
 well-being. Thus even from the earliest stage we could say the animal is enacting what the stimulation
 means to it. Yet to begin with the responses are entirely reflex and none of this meaning
 is being held in mind. Let's imagine however that as the animal's life becomes more complex
 it reaches a stage where it would indeed benefit from retaining some kind of mental record of
 what's affecting it. A representation of the stimulus that can serve as the basis for planning
 and decision making. And it turns out there's a very neat way of doing this. To discover what's
 happening to me the animal has only to monitor what I'm doing about it and it can do this by the
 simple trick of creating a copy of the command signals for the responses. An efference copy
 that can be read in reverse as it were to recreate the meaning of the stimulation.
 In short the animal can begin to get a feel for the stimulus by accessing the information
 already implicit in its own response. This I believe is the precursor of subjective sensation
 but of course it won't at first be a sensation as we humans know it. It won't have any special
 phenomenal quality. The key to acquiring phenomenal properties lies in how sentition goes on evolving.
 In the early days it does involve bodily behavior out in the open but there must come a time when
 such overt behavior is no longer appropriate. The animal no longer wants to recoil reflexively from
 red light for example but now it still wants to register that red light is falling on its body
 and that it feels menacing. So what to do? The solution natural selection hits on is ingenious.
 It is for the responses to become internalized or privatized. What happens is that the command
 signals rather than ringing about actual motor behavior begin to target the internal body map
 where the sense organs project to the brain. In this way sentition evolve evolves to be a virtual
 bodily response. It's still an activity that can be read to provide a mental representation
 of the stimulation that elicits it. Now as luck would have it and I mean luck here the privatization
 has a wonderful result. To illustrate what happens let me switch to something more like a human brain.
 Now we have sentition the evaluative bodily response here the reference copy is being
 monitored by a proto-self the new subject of sensation and here now the response is being
 privatized and what's the result? It leads to a feedback loop between motor and sensory regions
 of the brain a loop with the potential to sustain recursive activity and I believe this development
 is game-changing. Crucially it means the activity can be drawn out in time so as to give rise to the
 thick moment of sensation but more than this the activity can be channeled and stabilized
 towards create a mathematically complex attractor state a dynamic pattern of activity that recreates
 itself. Such an attractor can in theory have remarkable hyperdimensional properties
 real or unreal magical the answer will be in the eye of the beholder small adjustments to the
 circuitry will result in dramatic changes to the attractor's shape with corresponding changes in
 the subjective experience and the upshot is at least in the line that led to humans
 it's the creation of a very special kind of attractor one that the subject reads as having
 the phenyl the feel of phenomenal qualia this attractor is still a type of sentition
 which originates as a response to sensory stimulation and it still carries information
 about what's happening to me but the information now comes in a remarkable new package it comes
 if you like as part of a riddle written on the brain arguably the brain has in fact evolved
 to methodically bamboozle the mind so there we are job done I might have said that of course
 this is only the story in bear outline and no doubt it's only partly right at best but I'm
 convinced that every step is plausible as an evolutionary development and it leads to an end
 state that could in principle be responsible for phenomenal consciousness as we humans know it
 and as other sentient animals such as exist must surely know it too I acknowledge however that this
 is an explanation of how sentience evolved if it is that the story is still far from complete
 but we still have to explain why what it's all for what can have driven these evolutionary
 developments and those final stages in particular what have kind of been the biological advantage
 of having sensations dressed up in this wonderfully exotic way is phenomenal consciousness
 actually for anything there are a good many theorists quite willing and even happy to answer
 no to quote the philosopher gerry fodder consciousness seems to be among the chronically
 unemployed as far as anybody knows anything that our conscious minds can do they could do
 just as well if they weren't conscious why then did god bother to make consciousness
 what on earth did he have in mind well I went presuming to answer on behalf of god
 but what I will do is try to answer on behalf of natural selection to explain the use of phenomenal
 experience I suggest we can and should let our own our own first person intuitions be the guide
 who can know better than you or I do what sentience is for so ask yourself what would be what would be
 missing from your life if you lacked phenomenal consciousness if you had blind sight blind touch
 blind hearing blind everything I think there's an obvious and true answer it's the one I touched on
 when discussing blind sight is that what would be missing would be you yourself as I remarked earlier
 one of the most striking facts about human patients with blind sight is that they don't
 take ownership of their capacity to see lacking visual sensations with phenomenal properties
 lacking the somethingness of seeing they believe that their manifest capacity for visual perception
 has nothing to do with them with them then imagine what it would be like if you were to lack phenomenal
 experience of any kind at all if you were to believe that none of your sensory experience
 was owned by you presumably yourself would disappear of course I'm not alone in saying this
 the Scottish philosopher David Hume was in no doubt that sensations provide the basis for selfhood
 for my part when I enter most intimately in what I call myself I always stumble on some
 particular sensation or other of heat or cold light or shade love or hatred pain or pleasure
 when my sensations are removed for any time as my son sleep I may truly be said not to exist
 so remove phenomenal experience and the self ceases to exist but by the same token install
 or reinstall it and the self leaps into existence let's think back then to that point deep in the
 past when natural selection first breathed life into the loops in your ancestors brains
 and they woke up to find themselves transformed into sentient self-conscious beings in reality
 of course it won't have happened in the flash I don't think it need have happened as a gradual
 process either for the fact is that these attractors have an all-or-nothing character
 so the phenomenal izations of phenomenal ization of sensations could have come about quite rapidly
 perhaps with even just as few as a few hundred generations whenever it occurred it will certainly
 have been a psychological and social watershed with this marvelous new phenomenon at this core
 of your being you'll have begun to matter to yourself in a new and deeper way you'll have
 come to believe as never before in your own singular significance and it won't just be you
 for you'll soon recognize that other members of your species probably possess conscious cells
 like yours so you'll be led to respect their individual worth as well I feel therefore I am
 you feel therefore you are too
 in fact you'll soon make a remarkable discovery it's that when you imagine yourself in your
 fellow creatures place you can model in yourself what they are feeling in short phenomenal
 consciousness would have become your ticket to having a theory of mind and living in what I've
 called the society of cells so we come to the big question if this account is anything like right
 what does say about the distribution of phenomenal consciousness consciousness across the animal
 kingdom and maybe beyond it I've shown some chimps in my slide no one could doubt that they are
 sentient but among the huge variety of non other non-human animals alive today which species are
 likely to have crossed that line to sentience oh my account suggests there will be two crucial
 considerations it's going to depend on the kind of brain the animal has and the kind of life it
 leads first there will have been no physiological means for generating phenomenal experience
 unless the animal has a brain that can house sensory motor feedback loops capable of creating
 attractors of the kind I've described second there would have been no evolutionary incentive
 for the animal to acquire these attractors unless it has a lifestyle in which possession of a
 phenomenally enriched sense of self can enhance its personal and social survival this leads me
 to a surprising and possibly unwelcome conclusion certainly I think unwelcome to my hosts even
 it means I think that sentience must be a rather recent evolutionary innovation by far the majority
 of animals on earth have neither the brains nor the use for it to stick my neck out I'll be more
 specific I suspect that sentience may not have arrived until the evolution of warm-blooded animals
 where mammals and birds around 200 million years ago I draw the line there for two reasons
 the invention of warm-bloodedness had major effects both on animals lifestyles and on their brains
 to start with it made animals relatively independent of environmental conditions
 cold-blooded animals not only have to stay within relatively narrow geographic limits
 but they have their activity levels dictated from moment to moment by the ambient temperature as the
 sun sets or goes behind a cloud the body of a cold-blooded animal such as a lizard chills
 and its muscles and nerves slow down by contrast warm-blooded animals take their environment with
 them and so can be alert and active feeding socializing traveling both by day and night
 winter and summer high in the mountains or down on the plains now as the bodies of warm-blooded
 animals became more self-reliant and self-contained I imagine their sense of self-dead too after
 millions of years in which their ancestors had had their lives constrained by environmental
 temperature they found themselves let off the leash in body and mind they became increasingly
 autonomous agents with the freedom to go where and when they would suddenly a huge constraint
 on selfhood had been lifted but that's only half the story for just at the time when warm-bloodedness
 was increasing animal sense of having an individualized self it will also have been having
 a dramatic effect on their brains the reason is that conduction speed of nerve cells increases
 with temperature here's a graph of how it changes in a human's finger but all nerves behave this way
 including brain cells this means that as body temperature increases from an average of say 15
 degrees in cold-blooded animals to a steady 37 degrees in mammals and 40 degrees in birds
 the speed of nerve cells in the brain will have nearly tripled because this will have reduced the
 time lag in any feedback loops it will have made recurrent activation more likely to occur and I
 suggest this could have been just what was needed to fire up the attractor states turn up the
 temperature and bingo the activity takes off and the phenomenal self emerges okay this is like all
 speculation it's time to ask what's the evidence about the reach of sentence in the animal kingdom
 and the wider world it's sometimes said that we shouldn't expect there to be any evidence
 sentence is all on the inside and is invisible to external observers but of course that can't be
 right if sentience has indeed evolved natural selection must have been able to recognize the
 effects it has effects it's having at the level of behavior effects have increased the animals
 chances of survival and if natural selection was able to see those effects in the past presumably
 behavioral scientists should be able to do so today so where should we look I've been arguing
 that phenomenal consciousness gives an animal a competitive advantage specifically because
 of its psychological effects the way it changes how the animal thinks firstly about what it's like
 to be me and secondly about what it's like to be you in my new book sentience the invention of
 consciousness I propose a variety of ways in which this is likely to show up in behavior
 and I ask for example these questions do animals have a robust sense of self-centered
 on sensory experience do they engage in self-pleasuring activities sensations for
 sensation's sake do they have notions of I and you as mirror souls do they carry their sense
 of their own identity forward do they lend out their minds so as to understand others feelings
 well there's no time to expand on this but to whet your appetite I'll show a few film clips
 that bear on the evidence which I discuss in the book
 so for a start here we see a chimpanzee exploring his body as seen in a mirror
 here's a chimpanzee who clearly had a self-scent of being himself
 here are swans going for a joyride pure sensations
 boosting their sense of what it's like to be me
 yes I'm sorry let me get so excited he has a dog doing something similar
 and indeed he'll do it again and again
 here's an example of elephants showing empathy for another infant elephant in trouble
 so
 and here's a person doing the same
 rescuing a member of another species in this case
 here are magpies for wailing a dead companion
 so
 and here's a chimpanzee giving a child a thrilling joyride his child
 airplane
 and here I can't but add this it's just turned up recently
 an example of two sentient creatures a mammal and a bird enjoying each other's company
 but now I need to come back so it'll be
 clearly to each for the other as a conscious
 okay so I'd agree of course that no particular example can seal the deal and I've actually
 could suggest some more technical ones but they add together and I reckon the balance of evidence
 supports my hunch that it is only mammals and birds that make the cut chimpanzees and dogs and parrots
 all affirm their selfhood in ways like this lobsters lizards frogs really don't
 look at Bruegel's painting of animals waiting to be invited above Noah's ark see they are in fact
 all warm blooded knowingly or not I think Bruegel has painted the kingdom of sentience
 okay but octopuses but them they're everybody's favorite candidate for an outlying species that
 is sentient but I have to say the behavioral evidence simply belies this octopuses are
 undoubtedly highly intelligent yet on the face of it octopuses don't find pleasure in sensation
 seeking they don't have a strong sense of themselves as individuals they don't attribute
 selfhood to others nor do they care I guess sentence would be wasted in octopuses suppose
 we could in fact genetically engineer an octopus to have phenomenal consciousness I'm pretty sure
 the new found selfhood would make little or no difference to the octopus's survival and so the
 new genes would not be maintained by selection and would soon disappear but it's time to begin to wrap
 up this talk um let's return to Helen and frogs many years ago I wrote a paper titled what the
 frog's eye tells the monkey's brain um and what I think it's time to consider now is what a monkey's
 blind sight tells us about frogs and possibly about ai's so here's Helen reaching for peanuts
 and here's on the left here's a bullfrog catching ants
 both animals are using the same subcortical visual system of their brains
 with Helen poor blind sighted Helen there's good reason to assume that despite her obvious visual
 competence there was nothing it's like for her to see no phenomenal visual sensations and I conclude
 that equally there's nothing it's like for the frog to see it never had a cortex and furthermore
 this probably is nothing nothing it's like for the frog to taste or hear or feel pain
 and I think the same goes for most animals on earth
 however that's not my last word and in my closing remarks I'd like to make a significant concession
 when I argue that animals such as frogs are insentient I don't mean necessarily that they're
 not conscious at all indeed I've come around to thinking that many insentient animals
 probably are conscious but conscious in a more robotic zombie-like way and I'll need to unpack
 this as I said at the start the most general definition of consciousness is simply that you
 the subject have introspective access to mental states that you know what's in your mind and indeed
 this consciousness as used by cognitive scientists has this technical meaning that has nothing to do
 with phenomenal experience or sentience rather it has to do simply with how the brain manages
 information the best known model of consciousness cognitive consciousness which I'm pretty sure is
 right suggests that there's a central processing unit in the brain that has access to a global
 workspace where a current set of mental representations is on display the central
 processor having an overview of the workspace is able to collate and integrate information across
 different domains so as to allow intelligent judgments and decisions to be made on behalf
 of the whole system as such cognitive consciousness is an effective computational strategy
 it streamlines the work of the brain it resolves potential conflicts and gives coherence and
 direction to thoughts and actions but now because cognitive consciousness is relatively simple to
 engineer and gets results I think we can be sure it will have been discovered by natural selection
 and installed in animals brains long before any of them went on to become sentient I don't think
 that's true of phenomenal consciousness as we've seen phenomenal consciousness is not simple to
 engineer in fact if I'm right it requires some quite fancy footwork and indeed some lucky breaks
 in the development of the brain what's more the results are not either the results of phenomenal
 consciousness are by not at all by no means nearly so obvious or of any obvious relevance to most
 creatures lives when and if it finally arrives phenomenal consciousness will have required a
 particular kind of brain suited to housing housing reverberatory activity in sensory motor loops
 and it will have been selected because of a new kind of need the need to develop a sense of
 individual selfhood and to survive in that society of cells and so to sum up I now want to suggest
 there are actually three classes of animals on the spectrum of consciousness unconscious such
 as worms and jellyfish cognitively conscious but not sentient for example bees and octopuses and
 cognitively conscious and sentience for example parrots and dogs and humans but where does this
 leave blind sight if Helen was not visually sentient could she still have been visually
 conscious even if she didn't feel the light at her eyes did she still have cognitive access
 to visual perceptual representations and could this introspective knowledge have continued to
 guide her thoughts well I have to say this possibility has only recently occurred to me
 but I've been back over the films I made of Helen and I found telltale signs of her dithering
 mentally mentally apparently weighing up what caused to follow her for example she approaches
 an obstacle in her path she pauses she leans to the left and to the right I've slowed this down a
 bit to show it she leans both ways before choosing to go to the left you'll notice I use the word
 that she's choosing but presumably Helen could in fact only choose between alternatives if she were
 consciously aware of them in that case why hasn't this kind of awareness shown up in cases of human
 blind sight how come they seem to be totally unaware of their ability to see in the blind part
 of the visual field well actually there's a fairly obvious answer and it is that it is that almost
 all cases of human sight human blind sight are cases of half blind sight where only a part of
 the visual cortex is destroyed and the subjects still have normal vision at least at least half
 of their visual fields given that vision in the damaged fields damaged damaged field lacks all
 the familiar quality of that in the good field it can easily seem to the patient that has a complete
 void in the blind side so they say they're blind helen's case was very different she had
 complete destruction of a visual cortex so helen didn't have a good field to compare it to
 nothing nothing to continually remind her of what she was missing and so she could develop an idea
 that she actually did have conscious access to what was going on in the blind field
 and this raises the question what would happen if a human had complete destruction of the visual
 cortex it was just one case in 2008 a man from rwanda he's called tm had two strokes terribly
 bad luck two strokes 36 days apart that left him with no primary visual cortex on either the left
 or the right hand side of his brain he appeared at first had been rendered totally blind he
 himself said so he had no visual sensations nonetheless like helen it soon showed he soon
 showed signs of being able to avoid obstacles using his eyes um he has larry wise cunt leading him down
 a corridor i need to get this going sorry rather like i set up for helen
 and we'll see that he's apparently able to avoid obstacles quite unlike anything which had been
 seen in blindsight before there was however nothing is yet to show he was cognitively conscious of
 what he could see indeed he continued to say that he was blind but when i got to meet him a few years
 later there had been a remarkable change tm was no uh tn uh was now quite sure that he could see and
 he was proud of it without prompting he'd now volunteer to say what he was seeing let me show
 you two remarkable examples and i think these are quite extraordinary this man has no visual cortex
 yes
 you know he's showing us he's looking at the at the laptop
 while walking to the right but he's walking but he doesn't move
 uh
 look at that that man you think of course he must have
 cortex like oh he says he's blind and he has another example color vision
 is
 foreign
 okay um uh i think this is mind-blowing it hasn't been published yet this this this particular
 study tn sadly has died until uh we haven't been able to follow up um but when we write this up i
 think people are going to find it throws a completely new light on blindsight and the
 possibility of cognitive consciousness in the absence of visual sensation discussing this with
 dan some months ago i said i wanted to describe tn as a conscious zombie dan i may say was shocked
 he thought i was aligning myself with david with david charmers and his preposterous idea of a
 philosophical philosophical zombie who is a creature physically identical to a conscious
 creature but which isn't conscious but i wasn't suggesting tn as a philosophical zombie and i
 want to apologize for using the word zombie as a way of characterizing a psychological state
 psychological zombie the state of being conscious but not sentient whether it's blindsight or the
 equivalent condition that's the natural state of frogs octopuses honeybees and so on yes they're
 conscious but they're not conscious in the way humans or dogs or parrots are so now when it
 comes to the question of whether ai's will achieve consciousness dan's question at the beginning i
 believe it's crucial that we recognize the scientific possibility of zombie consciousness
 and adopt a terminology that gets to the heart of it yes ai's probably soon will achieve zombie
 consciousness maybe some already have it seems to me much more doubtful that ai's will ever achieve
 sentient consciousness like ours i don't see why they shouldn't do in principle but it's not going
 to happen simply as a result of increasing computational complexity let alone a larger
 training base for an llm if it happens it's going to require sentience oriented selection by human
 designers just as in the case of natural selection and just as in the case of natural selection i
 think it probably is going to require a lot of luck if we're ever going to get there and i may say
 i'm not holding my breath so that's where i'll leave this and uh steven i don't know how long
 it took on that and whether we have time that was fine could you could you turn off your uh
 slide share please yes okay first of all i want to ask melanie are you there
 melanie's left so i think we'll leave the other part of the of the memorial to this evening when
 melanie melanie gives her talk we're now open for questions to nick
 there's some in the actually there's some in the already in the uh other population i'll read you
 what we've got nick oh well i i remember one that was asked quite early so is it all right to be
 episcutarian there i don't believe that that that fishes have a phenomenal consciousness um they're
 not one blooded i think they're in the same classes lizards and frogs um i know you don't agree with
 that steven but it's when you say is it all right to be my question oh someone says is it all right
 well there are two separate quite separate issues here it's certainly not all right to cause pain
 unnecessary pain to animals which are phenomenally conscious and sentient it doesn't mean it's all
 right to do anything you like to animals which aren't sentient as i said they may well be
 conscious in another way cognitively conscious but in any case the creatures evolved in their own
 right to live their lives they were designed to lead and we mustn't make sentience the only
 criterion of whether their lives are valuable in fact i think it would be very dangerous too
 because then if we discover that they're not sentient then somehow it would be consigning
 them to the rubbish heap but of course that's not what we should doing ethics isn't entirely
 to do with sentience it's to do with the whole plan of nature and how animals fit together and
 the way they support each other and ecosystems and everything else um and i know you believe
 that steven i sometimes think you though you make sentience the only arbiter and i think that's a
 mistake um of course i may be wrong about sentient i'm i'm flying a kite in this talk and to suggest
 it's limited to warm-blooded animals is a particular restriction which i am quite prepared to have
 proved wrong um but nonetheless i think we need to be putting forward hypotheses based on the kind
 of evidence i discussed which makes at least these kind of uh speculations uh able irrelevant and
 and perhaps uh forcible thank you another person not me asks did the frog feel hungry after the
 experiment or not feel hungry and did you test ellen the way as you did the frog well helen
 helen wasn't in the same conditions the frog except in relation to a vision um so of course helen was
 sentient using all our other senses um i suspect that frogs aren't uh i think you can be hungry
 without being phenomenally hungry i think you know a lawnmower can be hungry uh for petrol and
 a robot lawnmower will go back and charge itself from the electrical supply um hunger is a functional
 state which can exist without phenomenal consciousness so uh i i don't know how we would
 have tested the frog to see whether it was hungry or or or not i suppose was the question whether
 the frog felt satisfied by these uh by these virtual flies it was picking up um i suspect the
 answer to that is no i don't think it would have been satisfying i think it wouldn't have had the
 dopamine response which you otherwise would hope to get from swallowing a blue bottle open to
 questions from the room if you want to just come down to the mic uh meanwhile i'll ask you what's
 the difference between uh zombie consciousness and sentience well i'm well the difference is
 just what i was trying to explain it's the whether or not uh in addition to zombie consciousness
 some of the representations have phenomenal content whether sensory representations have
 the qualia which distinguish them and make them so special um and so and i think that uh there's
 no reason to believe that once we've instilled something like a global workspace let's say in
 a computer that it will by virtue of having that sort of consciousness access to virtual to what's
 going on inside its mechanical mind and so on that it will be conscious it'll have introspective access
 but it won't be having phenomenal experience just by virtue of that and i think if that's the case
 for machines then it's the case for animal machines at the beginning of life and quite
 a way through it i think uh i think consciousness cognitive consciousness the global workspace as i
 said is a clever trick invented by nature probably many times over not that difficult to engineer
 and probably therefore very widespread in the animal kingdom and i mean right the way down to
 to you know into honeybees and insects i shouldn't say done but to include honeybees and insects and
 and uh other creatures who show that kind of sophisticated intelligence and behavior i don't
 think it goes right the way through the whole of the animal kingdom i don't believe there's any
 reason to think that that jellyfish or earthworms probably not earthworms have even that level of
 consciousness i think they're plain are unconscious as are most computers today as our lms as we know
 them at the moment but i do think that lms will quite shortly uh be candidates for what we would
 call cognitive consciousness we'll be able to ask them about what's going on in their in the robot
 minds and they'll be able to give uh answers which correspond to the reality of their mental states
 and for that token they will be conscious okay uh let me take it back to the subject of the
 i mean of this special session which is which is daniel dennett what would daniel dennett say about
 your distinction between consciousness and sentience with all these other words like qualia
 and phenomenal phenomenal consciousness where are you in agreement and where are you in disagreement
 with dan dennett well we've had a running disagreement about carlia uh for as long as i
 know and i just can't persuade dan that that is a useful term or refers to anything real in our
 experience i think we you know i think he just doesn't get it which is a surprising thing to
 say about a man who gets almost everything but on other issues dan and i have pretty big disagreements
 he thinks that phenomenal consciousness does go all the way down he talks about hemi semi demi
 levels of consciousness he thinks it's a continuum um i think that's just unbiological and and against
 the evidence it's people claim it as a biological way of thinking because as darwin emphasized
 there is continuity in evolution but there's continuity with very clear gaps in it there are
 new abilities which emerge in the course of biological evolution which were simply absent
 before and i suspect that phenomenal consciousness is one of them that it came in as i said rather
 quickly but relatively late in the course of evolution only in those animals which had
 particular kinds of brains and a particular use for phenomenal selfhood once it became available
 we have a question from ayah amer go ahead and there's two others raise your go ahead ayah and
 meanwhile turn off your your hand so that i can see the other ones sure hello can you hear me
 i can hear you oh so i have a question um that's going to sound a little bit nitpicky but it
 dovetails into a wider question that i had which is so you said about the octopuses that you don't
 believe that they are sentient and you believe that if we did give them sentience it wouldn't
 matter um i just wonder does that not point to the fact that like sentience does not have an
 evolutionary purpose if it does it if it won't affect the behavior of the octopuses if it won't
 give them any sort of evolutionary advantage and then i guess the broader question is that
 you mentioned that you believe sentience is useful because it allows us to have a sense of self
 and i'm wondering what you believe the you know competitive advantage that having that sense of
 self is what competitive advantage it grants well it gives a kind of self-importance and individualism
 to the animal psychology which i think is extremely valuable when you get into competition with other
 animals like yourself but it's also valuable when you get into cooperation with other animals like
 yourself and i emphasize that phenomenal selfhood comes into its own when you are living among
 other animals which have consciousness like yours it's the basis for theory of mind it allows you
 to use your own mind your own phenomenally conscious mind as a model for the other creatures
 you share your society with and that's an absolute amazing achievement it's led to
 you know all the major advances in evolution which have occurred particularly among social mammals
 and birds in the last 200 million years which have basically you know life took off again once
 society developed in that way reason it wouldn't help octopuses is that they don't have societies
 they don't live in the company of other octopus selves they they interact with them sometimes
 but they don't have a complex social life they don't cooperate they don't they don't even coral
 in meaningful ways they're not friends with each other despite the netflix documentary and therefore
 what i say it wouldn't be any value any value to them it's because they don't have an equal
 occupied ecological niche where that kind of social intelligence would pay off so it doesn't
 contradict the idea that that phenomenal consciousness is adaptive in the right circumstances
 but simply i'm saying that it wouldn't be adaptive in all circumstances and we're going to find that
 with ai as well and with robots uh it's not going to there would be no point in giving most robots
 at the moment but any kind of phenomenal sense of self because but they don't have an area to apply
 it in if and when we want ai's to develop theory of mind and perhaps show empathy for other creatures
 like humans and like other robots for that matter then it's a new ball game we may with that point
 want to think about how we could instill sentience in robots at that point um and it may well be that
 we'll find it the right track to be to borrow a leaf from nature's book and to do it in very much
 the way that it's been done in the case of our own sentience by developing something like these
 feedback loops for example that just may be the best and and most straightforward way of doing it
 but there may be other ways of instilling sense or has a question go ahead is another good
 hey thanks a lot for this really nice pictures and videos and great talk
 so i have two things i want to mention so first about digidan open ai retired digidan in january
 2024 as they called it so digidan was deleted before dan passed away and then so we had a
 conversation about that so i asked dan what should i do in the case if you pass away and so we had
 the agreement that i would delete digidan at the day of his death anyway but open ai was faster by
 tidying cleaning up their system and deleting digidan beforehand and so i'm happy that this
 is done already but um what i think is very important if we sort of start to speculate
 what digidan would say or would not say um even though he cannot say anything anything anymore
 is that um it was very important for dan that any outputs of digidan has to be authorized by him
 so um i promised to him that i will never publish anything what digidan said without asking him
 beforehand and so that means all the speculations what digidan would might have said should also be
 mentioning that we cannot publish or obviously talk about digidan outputs without his permission and
 as we cannot get his permission anymore we should maybe stop this speculation this is not a critic
 this is just my personal stance on it but what is more important to me i'm still deeply impressed
 by the story of helen and the blindside thing and i'm thinking about that i had the impression that
 your social behavior towards helen made it possible for her to sort of come to come over
 to overcome the uncertainty with respect of the lack of sentience with concerning a visual
 experiences and um so the question i'm formulating now is sort of a little bit speculative
 because of course um artificial systems do not have other sentience parts so they are non-sentient
 system all the way through but could you think that if we sort of treat them like we treat little
 children as social interaction partners that this could sort of drive the development of them
 making use of cognitive consciousness which they might have in the future so so it's speculative
 because i would not agree that any system we know of has already cognitive consciousness but if it
 would have could i sort of help the system to make use of it by treating it as a social interaction
 well um first look first about digi dan and real dan i'm interested that that was his attitude
 oh i i wouldn't be surprised if dan actually uh is now slightly regretting that decision maybe it
 was chat t cheap cheap cheap gpt3 wasn't it so it wasn't as good as it could have been but i think
 dan rather fancied the idea that he could live on and his ideas would would be expressed even in ways
 he hadn't yet thought of himself through a model of that kind and and why not and as i said it lacked
 it lacked uh reality in other respects and he would have hated to have missed out on on on the
 life of the body but nonetheless you know let's suppose we could have digi socrates um wouldn't
 i i think that would be a wonderful resource i mean suppose he'd really been trained on all the
 texts which we've never even seen from socrates um i think it would have been a boon to the world and
 a boon certainly to socrates's reputation and equally i think dan deserves to live on he does
 live one for his works anyway of course he does and that's what he was acknowledging in that in
 that film clip at the beginning but i think it could have been at a level which i mean i understand
 your your your sensitivity about that but nonetheless i'm i think it's you know we we could say well
 maybe you should just have put it in a cupboard and not destroyed it as we're running out of time
 quick question sorry quick answer about the about uh interacting with with animals yes i think it's
 absolutely crucial to bring out you don't bring out uh these high level capacities in animals
 all in machines until you ask them pose the questions to them to which those their capabilities
 would become relevant and of course human social interaction we're very used to doing that i mean
 you are a poly i don't know if you have children but you know mothers coax this kind of self-belief
 out of children from the very beginning um so all i was doing with helen away was reputation of
 that kind of maternal interaction um but it does take that kind of interaction and i agree i don't
 i think there's never been never been another monkey like helen and it had very likely something
 to do with my peculiar relationship to her three quick questions three short answers short question
 short answers freedom and pulver miller alina gutta gutta guttoreva and steve hansen and then
 it's over freedom and go ahead yeah thank you very much for this thoughtful uh talk uh let me ask
 and you mentioned the possibility of um of of having a state uh being in a state
 but not being sentient sentient of this state you mentioned the frog as an example
 of an individual being which may be hungry without the sentient without the hungriest
 sentience if i understand correctly is this understanding correct if yes what are the
 criterion the criteria for deciding that state x is present but sentient sentience of x is not
 well that's not a short i can't give a short answer to that it's exactly the right the right
 question i think in the case of frogs i wouldn't take hunger i take vision i think they're not
 sentient of vision i think they have blind sight um uh there are some peculiarities about blind
 sight which i would love to have time to go into one or two oddities about it which i think do give
 clues to how we might detect it in in animals but i'm afraid that's going to be have to be okay
 of course it's the right question how do we tell next question we can't pursue that because there's
 just no time alina say it quickly uh sure i just wanted to say thank you for a wonderful talk nick
 and for the overview of daniel dennett's biography experiences and thoughts possibilities of
 immortality um and reminding us that we leave in the minds of our loved ones so thank you for that
 my question is about um is it correct rather maybe um clarification so is it correct that
 you suggest that sentience requires um empathy theory of mind and vision i didn't quite get the
 link between sentience um and vision it's going well thank you theory of mind i think requires
 sentience not sentence requires theory of mind so theory of mind at a high level is to my i think
 very good evidence that the subjects of it are have sentience um uh and have phenomenal consciousness
 uh it's i mean again i can refer you to my book but that's not a fair thing to do
 to argue what in particular what kinds of dimensions of mind are revealed and described
 in terms of sentience which would be very difficult to describe and summarize in any other way so i
 think it's a shortcut to a theory of mind um but i think they are absolutely linked okay last question
 short question short answer steve hanson uh can you hear me yes excellent uh lovely talk i especially
 enjoyed the history of blind sight uh i'd known a lot about this work uh from visits at uh oxford
 and cainbridge at different times but my question is this loms this is short probably not easy to
 answer uh are known to have huge attractor states we've measured all kinds of attractor states in
 this that make a huge amount of sense uh but we no one knows how they work let's just flat out we
 just have to accept this was a discovery not an invention now your theory which is really uh
 fascinating appeals to attractor states a recurrence and feedback loops and so on
 and so it seems that we're back into an awkward space where we have to figure out what kind of
 attractor states that we care about and what kind of attractor space are going to have something to
 do with consciousness and sentience and all the rest of it yes of course and it's it's not going
 to be me who does that i haven't got the mathematical sophistication to to actually
 make concrete suggestions about uh how where to go with that but i hope others will i think it's
 i mean the great thing you know it makes sense attractor states make everything too easy because
 they do have these hyperdimensional properties i mean some attractor states require an infinite
 number of dimensions to characterize them that gives plenty of scope for natural selection to
 pick and choose in terms of deciding what's going to work in terms of a creature psychology um but
 it certainly yes it's uh we need much more sophisticated analysis than i could ever give
 and at the age of 81 i'm not going to start um i hope there'll be other others who might take up
 these ideas thanks very much nick it was a very stimulating and uh provocative presentation
 well thanks
 we'll continue uh at 130 our time
