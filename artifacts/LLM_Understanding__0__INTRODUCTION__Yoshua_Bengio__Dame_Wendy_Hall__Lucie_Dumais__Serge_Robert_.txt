 - Good morning, everybody, and welcome to this, I hope, magnificent summer school.
 I am Serge Robert.
 For the last three years, I have been the director of the Institute of Cognitive Science
 here at UPM, and during many months, I have seen four people working very hard to make
 this summer school possible.
 There are our two employees at the Institute, Camille Charbonneau and Denise Goulet, who
 have worked very, very hard for months and months.
 And there are also my two colleagues, Pierre Poirier and Stephen Arnad, who are co-responsible
 for this summer school.
 And Pierre is, since last Friday night, the new director of the Institute.
 And of course, the most important person in this summer school is my colleague, Stephen
 Arnad, who has worked night and day, forgetting at times to eat, forgetting at times to sleep.
 And the result is this outstanding program for this summer school.
 So I hope that you will have a wonderful, unforgettable summer school for the next two
 weeks, and I give now the microphone to my colleague Pierre Poirier.
 Thank you.
 [French translation]
 Dear Monsieur Benjot, Messieurs, les directeurs de l'Institut, dignitaires présents, chers
 d'organisateurs, conférenciers, participants, étudiants, étudiants, bonjour.
 Il me fait grand plaisir de vous accueillir et d'ouvrir cette école d'été de l'Institut
 des sciences cognitives, la neuvième depuis 2003, qui porte sur le sujet des grands modèles
 de langue.
 Depuis sa création, l'Institut des sciences cognitives a fait progresser et smer la réflexion
 interdisciplinaire sur la cognition et, bien entendu, sur les technologies si rattachantes.
 S'il est une voie que l'Institut s'est tracée au fil des années, c'est qu'il n'a jamais
 cessé d'être pertinent en fonction des enjeux sociétaux de l'heure, ceux-ci évoluant rapidement,
 très, très, très rapidement, ajouterais-je.
 Certains ou certaines ne le savent pas, peut-être, mais l'Institut des sciences cognitives est
 rattaché à la Faculté des sciences humaines dont je suis la doyenne.
 Ce rattachement souligne combien ce qui se rapporte au monde de la connaissance et de
 surcroît moyen technologique, soutenant nos capacités à connaître le monde, voire à
 contrôler s'incarne forcément dans un environnement culturel, social, humain.
 As Dean of the Faculty of Social Sciences, to which the Institute of Cognitive Sciences
 is attached, it is a privilege to co-host, with Milla and the University of Southampton,
 the ninth edition of the Institute's Summer School.
 My warmest welcome to all of you, particularly to our special guests, Dame Wendy Hall from
 Southampton University and Professor Joshua Benjo from Université de Montréal and Milla,
 as well as to more than 30 speakers from over the world who will bring to us their expert
 knowledge on large language models.
 I am also delighted to learn that a significant number of students, graduate and undergraduate,
 will attend classes on a large array of subject matters over the coming fortnight.
 La présente école d'été rencontre parfaitement la triple mission de notre faculté de l'université,
 soit le partage des connaissances de pointe, la formation de personnes étudiantes et l'accessibilité
 des savoirs à un large public.
 Je me plaît toujours à souligner la dynamique, le dynamisme de notre communauté et sa grande
 ouverture sur le monde et ses concitoyens.
 L'Institut de sciences cognitives est à cet égard exemplaire.
 À la faculté des sciences humaines, ce sont les professeurs de linguistique, de philosophie,
 de psychologie en particulier qui s'investissent dans les études sur la cognition.
 La faculté a d'ailleurs des concentrations, ainsi que plusieurs cours interdisciplinaires.
 En sciences humaines, on comprend qu'un sujet comme les grands modèles de langue et les
 problèmes d'intelligence artificielle qui les sous-temps exigent d'embrasser une vision
 large, voire intégrée, des analyses disciplinaires, tant des sciences humaines que des sciences
 expérimentales, pour faire face aux énormes enjeux qu'il nous incompte d'affronter pour
 la culture et la technique sur le plan de l'éthique et pour l'avenir que nous sommes en train de
 construire.
 Grâce à cette école d'été, et en particulier aux fabuleux moyens techniques de communication
 dont nous disposons en 2024, tous les contenus de conférences et d'opinion seront accessibles
 à la communauté locale et internationale.
 C'est une chance extraordinaire d'avoir accès à un nombre imposant d'experts et de
 sommités internationales ici à Montréal ou devant les écrans.
 Plusieurs régions du monde sont présentées parmi un auditoire de près de 1000 personnes
 au cours d'une cinquantaine d'activités, parmi la trentaine de conférenciers et de
 conférencières.
 Il y a le Canada, bien sûr, le Wyoming et le Sud, le Québec francophone.
 Je félicite donc le comité organisateur, le domaine et le personnel de soutien et logistique
 de l'UQAM et toutes les personnes ayant contribué à la réalisation de cette école d'été
 dans virqueux.
 Je réitère ma reconnaissance au directeur de l'Institut, les professeurs Serge Robert
 et Pierre Poirier de philosophie et ma joie de pouvoir les compter parmi les membres les
 plus dynamiques de notre faculté.
 Enfin, je vous souhaite à tous et toutes et aux participants de deux très belles semaines
 et je vous souhaite encore bienvenue à cette école d'été.
 Welcome to this 2024 summer school.
 Hello everybody.
 Bonjour tout le monde.
 Je serai bref.
 Dame Wendy Hall, who I would like to hug at this very moment, is Regis Professor of Computer
 Science, Associate Vice President and Director of the Web Science Institute, one of the sponsors
 of this event at the University of Southampton.
 She became a Dame Commander of the British Empire in the 2009 New Year's Honours List
 and is a Fellow of the Royal Academy of the Royal Society.
 I'm not going to read the rest of these.
 It's very long.
 It's as long as my arm and I want more time to hear Wendy.
 Wendy, welcome to Montreal virtually and actually the second time, but this time virtually.
 I know.
 Thank you so much, Stephen.
 My old friend and big hugs to you.
 The Web Science Institute is very honoured to be asked to co-sponsor this event.
 I only wish I was with you.
 If I'd have had more notice, maybe I could have come, Stephen.
 So next time I need a bit more notice, but I so enjoyed the last time I was with you.
 But anyway, for those who don't know, Stephen was at the University of Southampton for many
 of his formative years and he actually moved from the Department of Psychology to Electronics
 and Computer Science and we had offices next to each other and spent many wonderful hours
 talking about symbolic grounding.
 When we were doing the early work on the semantic web, do you remember those days, Stephen?
 Semantic Web or that I learned so much from you and need to relearn in this new era of
 AI and you know, those were the nineties, it's 30 years ago.
 We were talking about these issues and it was so wonderful when you sent me through
 the programme to see what a fantastic programme you'd put together, very interdisciplinary
 talks talking about the things that we really, really, really need to be talking about at
 the moment.
 I spent all my time, unfortunately, going to conferences which are largely full of
 very technical people, so not very diverse at all and in any sense, right, not just gender,
 but discipline and geography and they all talk about LLMs from a purely technical point
 of view and I've, you know, it's the race to AGI and I feel like it's the race to the
 bottom, right, because the term AGI has been so devalued and what is it, it's become quite
 meaningless.
 Yoshua, you're welcome to disagree with me when you come on, but to me, it's become
 quite meaningless. I think you agree with me on that one, but and I feel like, you know,
 I was in Singapore last week for the UN, on the United Nations AI advisory body and we
 spent our time reading reports written by Yoshua and the, which is good, a good thing,
 but then I was also stayed on for the Asia tech summit and this and the conversations
 I have are so depressing. There's the people who think we're going to reach AGI in its
 full extent next year, okay, and then there's somebody who stood up at a panel and said,
 well, when we reach AGI in 2027, without defining what they mean by AGI or any of understanding
 any of the things that you're talking about, you know, language, reasoning, does LLMs have
 any sense of knowing what they're doing and what would it mean if we got to AGI? You know,
 this is the people who go on and on about the existential threat and yet they still
 want to reach AGI and yet, hang on, what exactly are we talking about here? What safety do
 we really need in all this to ensure that the human race does live beyond 2027 or whatever
 date is plucked out of the air for when we'll reach this undefined term AGI and I noticed
 in Yoshua's big report that he did for the UK safety summit or whatever that turned out
 to be, whoever commissioned the report, he's changed the terms to general purpose AI, which
 is a much, or his team have, the people who put that together, which is a much more, he
 still needs to find what that means and what the consequences are for the human race if
 we get there, but at least we stop using this devalued term AGI and so I just want to congratulate
 you, Steve, and I'm not going to talk very long, I want to hear Yoshua talk, but I want
 to congratulate you on putting through this programme, very, very pleased to be co-sponsoring
 it, we'll put it up on our website and I won't be able to listen to it all the time,
 but I will dip in and out and I will also make sure I listen to all the talks over a period
 of time, absolutely fantastic, well done, we need more, more of this sort of activity
 to make sense of where we're going in this new era of AI, done.
 Thank you so much, that's only a local applause, there's also applause all over the web, can
 you switch the presentation to him, that's it, I'm going to stay and listen to Yoshua,
 this is why I'm on the call really, Yoshua, how did your face just appear, say something
 out loud, hello, do you hear me, okay good, keep talking while I talk, I'm going to spend
 time presenting you, nobody in Montreal needs a presentation, this is Yoshua Bengio who
 is responsible for what it is that people, whole responsible for what it is that people
 are talking about here today, Yoshua go ahead, you froze, the other people, yes I did work
 on this, do you see me, do you hear me, yes, yes, hello, yes, alright, alright, I'll start,
 you know, there's a reason why we're here, besides incredible persistence and will, there
 is an AI revolution and it is being really triggered by these large language models,
 but I want to go back a little bit in history, I started my master's degree in the mid 80s
 and I got really excited about the connectionist models, the ancestors of these neural nets,
 that's when back replication really started as well and I worked on many of similar things
 with tiny, tiny models, not large at all, and then in 2000 I introduced the neural language
 models, so they were very similar to the ones we use now, except they were much smaller,
 but they were much bigger than those that people before had made and they introduced
 notions of representations, word vectors for words in a language model, that turned out
 to be very important and then in 2014 my group introduced the use of attention in these neural
 language models, and it was published later at the AI stats in 2015 for Google translation,
 one year later, that was really fast, Google took essentially the same kind of architecture
 with attention for machine translation and they created a new version of Google translate,
 which was amazingly better than all the previous versions and basically they scaled up the
 thing we did at the academic level and engineered it beautifully, and that already sent a signal
 in the whole industry that these kinds of models were going to be transformative, one
 year later in 2017 Google group also introduced transformers, which basically take these attention
 and mechanisms and stack them over many layers.
 There's a connectivity problem.
 So around 2017 is also when people started to realize that as we make these neural net
 architectures for language models bigger and bigger, the training objective gets better
 in a kind of very predictable way and that has continued since that time and we haven't
 seen the end of those scaling curves.
 This is also the reason why industry is being investing so massively because it looks like
 we can just pump more money into this and they get smarter.
 So nonetheless, I've been talking since also about 2018, 2017 actually about what is missing
 from these large language models.
 They're really good at capturing what corresponds to intuition or system one, not so great at
 reasoning, although they're getting better for each version of these systems.
 Everything about higher level of condition seems to be not so great and that's what I've
 been focusing my research in the last few years, but now industry has realized the importance
 of these high level condition abilities and reasoning.
 We have AI systems that are really good at planning and in a way reasoning like AlphaGo,
 but don't know a lot of stuff.
 Like the rules of goal is just line lines.
 And on the other hand, we have things like chat and GPT, which knows a lot of stuff,
 but how to put these things together, how to reason with the pieces of knowledge that
 something like AlphaGo has remains an open problem.
 So what does this all mean for the future?
 I don't think that we expected to see AI systems mastering language the way that they do now
 just a few years ago.
 For me, it was a big surprise and a bit of a shock because I hadn't been thinking about,
 well, what if we succeed?
 What if in a few years or a couple of decades, we reach human level AI?
 I don't think that really we understand sufficiently the systems to answer those questions satisfactorily.
 And already we're seeing signs that those systems are not doing exactly what we want,
 that they can be toxic, they can deceive people because they're trying to maximize a reward.
 And so I think it's really important that we work hard at better understanding these
 large language models before we get to the point where they could be as smart as us and
 potentially do things that could be dangerous for humans.
 In fact, sometimes I feel like we're all sleepwalking, racing towards a fog, this AGI race that people
 talk about.
 And there are warnings that behind that fog, there could be a precipice we don't really
 know.
 And so, such a summer school is very important to help us move in the direction of better
 understanding of the understanding that these systems have.
 And so it's still a great pleasure to be here to wish you all the best and congratulate
 Stephen and the whole team who organized the summer school.
 Thank you.
 [Speaking French]
 We're cutting the recording, and then we're going to restart with Richard Fattrell.
 Apologies for the loss of time, Richard.
