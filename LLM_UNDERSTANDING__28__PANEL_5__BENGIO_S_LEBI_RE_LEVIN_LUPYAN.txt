 - You can start your list, Mike, and then we'll segue into it, the other people later.
 - Okay. Okay. Yeah, I'll start on the list. You tell me when to stop. Okay. Let's see.
 Moving in the other direction, do you see these cognitive phenomena at the inter-organism level,
 such things as anthills or cities? Okay. So I don't know anything about cities. I'm not sure
 what work has been done on that, and many people have done these things in anthills.
 We showed a few months ago, we had a paper looking at how groups of embryos cooperate into what I
 call the hyper-embryo. So large groups of embryos can solve problems that individual embryos cannot.
 We see them communicating with each other. I showed a brief video of this in my talk.
 They have a different transcriptome than small groups and individuals. So yeah, these phenomena
 do scale up, certainly in biology and maybe beyond. Okay. Next question. Can you explain
 what the WASPs- - Mike, can I ask you to name the person if there's a name?
 - So I can't because when I copied and pasted, as you suggested, it didn't copy the names.
 - Oh, okay. Sorry. - Yeah, I'm sorry. I don't see it here.
 - Okay. Let's see. Can you explain better what the WASP did to the tree? So nobody knows exactly
 what it does, but basically it lays down some chemicals and maybe there are other signals as
 well that we don't know about. And what it does is fundamentally the same thing that we do when
 we change the bioelectrical properties of cells and get them to build something that they wouldn't
 normally build, which is there's a couple of ways to look at it. One way to look at it is that you
 are deforming, by putting down signals, you are deforming the energy landscape for those cells.
 So if you think of those cells as traversing various energy landscapes, let's say metabolic,
 transcriptional, but whatever, physiological, what you're doing by providing these signals is
 deforming their landscape so that when they do what they normally do, the outcome becomes something
 other than what they normally do, but something that's good for you. So you as a bioengineer or
 as the WASP deforms their oxygen space to make certain paths more likely to be traversed than
 they otherwise would. We don't know the exact signals. There are people who study it, but it's
 still pretty poorly understood. But what it does say for sure is that when we talk about
 developmental constraints and the limitations of the material, those are just as likely to be
 the limitations of our understanding, not so much of the material, because I think everybody would
 have said that if you didn't know about those Gauls, you would never have thought that the leaves
 could do that. And nobody predicted that anthropobots would heal neural wounds and things
 like that. There's more limitation in us than there is, I think, in the material itself,
 at least for now. Ethically, if these simple organisms have a level of consciousness,
 is it okay to do these experiments on them? This is an important question for sure. But look,
 I'm not even a clinician and I get emails all day from people who I've got a spinal cord injury,
 my kid has a birth defect, I've got cancer, I've got this and that. The biomedical need out there
 is enormous. I think in my life, I've only met one person who I think was serious when she said that
 if her kids were sick, she would not take them to the doctor because she thinks that these things
 are unethical. And if that's the case, and if you're a vegan that will literally not take your kids
 to the doctor. I mean, I think that's a terrible worldview, but if that's your worldview, at least
 it's consistent. Everybody else are pretty sure that if they are in some sort of fundamental
 medical need or if their kids are, they will absolutely take them to the doctor and hope that
 somebody figured out how to help them. And the only way we get to do that is with experiments
 on frog skin and flatworms and leaves and things like that. I think that not doing these experiments
 is absolutely an ethical move itself. In fact, I think it's deeply unethical. I think we have a
 moral imperative to help the enormous number of people and other sentient beings in medical
 distress all over the world. For me, it's an important question, but it has a really simple
 answer. And you'll have to make your own decision about what you would do when you're going to need
 the outcome of this kind of knowledge for yourself or for your kids. As long as we have pediatric
 oncology wards, somebody has to be doing these experiments. I feel very strongly about that.
 Okay. Next, where's the line where a system should be presumed to be able to feel pain?
 So I hate lines of any kind. I think there are very few scenarios where I've ever seen
 anybody do a good defense of really a crisp line. Maybe in some quantum events that happens, maybe.
 But everything else, if you zoom in enough, you don't see a line. You see a continuum. It just
 looks like a line when you sort of back up. So I don't think we should be asking can it or can't it.
 We should be asking what kind and how much. And I think there are many systems, including very
 unconventional and very basal systems, that are using a systemic stress response to guide their
 actions in that space, basically as a readout of error, as overall error relative to some goal
 state. And I think that if you have a system that has adaptive behavior in which the whole system
 has a global stress response over being far from some equilibrium goal that it has, you should take
 very seriously the idea that it is on the same spectrum as you and your pain. It is not at the
 same level, probably. We don't know. But my guess is it's on that same spectrum. So I think even very
 basal systems have the fundamental architecture needed that we have expanded into what we consider
 to be pain. Okay. What ways would one outside biology use to get into your field? The DC summer
 school, other avenues. Yeah, the DC summer school is actually really good. So the diverse intelligence
 summer institute, yeah, really good program. I think that to get into this field, the ideal thing
 is to first study the various components of it. So philosophy, computer science, developmental
 biology, all those kinds of cognitive science, those kinds of things. And then work with people
 who are in the field. So there are dozens of amazing labs actually in this field and they
 can all use help. So contact me or anybody else in the field and I think you can do it.
 Okay. Let's see. Apart from the share of ion channels and gap junctions, what other similarity
 did you observe between morphogenesis and neural brain processing? Yeah. So the thing is that,
 so two things, one is that we appropriate almost everything from neuroscience.
 So we take conceptual tools, active inference, perceptual by stability, all these kinds of things,
 visual illusions, all the stuff that's known about visual processing, all of those things
 we can appropriate. Likewise, the tools, optogenetics, all of the pharmacology of
 neurotransmitters and other machinery, the tools of behavioral science, so the different ways to
 train things, the different types of learning. I mean, all of it works. We have not found anything
 that really fundamentally can tell the difference between neural tissue and non-neural tissue,
 except for things like timing. If you have something that really depends on millisecond
 spiking, then obviously it's much slower in development. But we also, I used to have my
 students do this by hand and now we made an AI tool to do it and it's online. I'll put the link
 in the chat later. If you take a neuroscience or a behavioral science paper and you put it through
 a word processor and you just do find, replace, and anytime it says neuron, you say cell,
 and anytime it says millisecond, you say hour. If you do that, and there's a couple of other
 changes you could make, but if you do that, you have yourself a nice developmental biology paper.
 And so it's amazing how well it works because I think that's what evolution basically did.
 It kind of pivoted space for time a little bit, then it slowed things down. But otherwise,
 that's where the brain and its amazing tricks kind of came from. So we now have a tool. It's
 called FieldShift where you put in a neuroscience abstract and it tells you what the parallel
 reality developmental biology paper would have looked like if they did it that way. And it's
 very illuminating because it always gives interesting testable hypotheses. So as far as
 I can tell, pretty much everything carries over. Let's see. Well, except some very specific things.
 Like I said, we don't have evidence for language use, for example, but I don't know that that's
 not our limitation and not being able to recognize languages and grammars that don't look like the
 things we're used to. I mean, I'm certainly not a linguist. Who knows? But I make no claims about
 language. Okay. What is the largest tissue organ or animal you worked with that enabled successful
 morphogenesis? What you imagine will be the largest. I mean, we've worked in salamander,
 we've worked in mice, we've worked in frog, we've worked in human organoids.
 Yeah. I think those animals would be the largest for now. Okay. What do you imagine will be the
 first example of brain machine development? I mean, this is not precisely my area, but I think this
 already exists. I mean, I've seen examples of some nice neural interfaces for people doing amazing
 things. Ultimately, like right now, these things are basically just control interfaces, but there's
 a lot of even older work on sensory augmentation. And I think in the future between these kinds of
 implants and AR, VR and those kinds of things, I think if you want sense organs that make you feel
 certain ways about the stock market and the solar weather, in addition to your five normal senses,
 I think you'll have them. And even humans, I think, talk about neuro-atypical, I think you're
 going to have people that are living in very different worlds because they've chosen various
 other things to pay attention to as a primary sensory input and the plasticity will make all
 that work. Okay. So let's see. All right. Impression that this approach to intelligence
 is a little deterministic on the basis of your prognosis toward a hybrid evolution.
 Should we consider that this evolutionary process lies outside our human agentivity?
 Well, no, I don't think it's outside at all, except that I think we need to get our heads
 around the fact that we are actually not very good at predicting some of the important things here,
 including the emergence of goal-seeking systems. It's hard to exert good agentivity when you don't
 understand what's going to happen and you don't understand the material, but I think it absolutely
 is within our agentivity. So it's on us to develop the science of this. And once we do,
 then it's on us to wield it for everybody's benefit. So I think it's fully within our agentivity,
 but that first step is critical, which is getting better at understanding the material we're working
 with. Okay. Let's see. My interests lie in the field of education and sociology. And I would
 tend to say that this evolution is rather circular in the sense that the different dimensions of our
 environment coexist and interact in a conscious way. Okay. It seems to me that you have a different
 approach to the evolution of our ecosystem. And I'd like to hear on that matter. Evolution of the
 ecosystem. I mean, you know, I do think that it's quite likely, although I'm not sure what all the
 best data are on the level of ecosystems, but I do think it's quite likely that there are larger
 scale systems that also have agency and memory and some goal states that we don't know about and so
 on. I think that's probably likely, but not proven as far as I know. And I also think that there's a
 lot of niche construction going on in the sense of all of these agential systems modifying their
 environment in ways that are going to then sort of recursively feedback and modify what happens in
 the future. I think in many ways, thoughts, thought patterns through cognitive systems do that too.
 They do a kind of niche construction. I mean, it's known that like depressive and persistent
 thoughts tend to modify your brain to make it easier to have more of those thoughts. And I think
 that's probably true on every scale. So there's a lot of kind of back and forth between systems
 and their environment. And, you know, in the current formulations of the active inference paradigm,
 like people like Chris Fields will have pretty sophisticated models by which the environment
 is, there's a symmetry, there's a fundamental symmetry between agents acting on their
 environment and the environment acting on them. And so stay tuned. I think there's a lot of good
 development of that kind of area. Let's see. The human DNA has 3.1 gigabytes of data. Do we know
 which portion of it is used to build the human brain? Data, so this is a very tricky question
 because data can only be seen from the perspective of an observer. So if you want to interpret the
 human genome from the perspective of making proteins, then you can say how many gigabytes
 it has because we know how many base pairs it takes to specify an amino acid. So then you can
 do that. If you want to quantify the relationship between DNA and an anatomical feature like the
 brain, that's extremely difficult because that requires a much better understanding of who's
 reading the DNA and how. And that we are nowhere near being able to quantify that. So, you know,
 I don't think we can answer that question. What you can say, for example, is what percentage of
 genes are required for brain development. I actually don't know what that number is, but
 that could be calculated. There are some percentage of genes that are in some way important
 for brain development. I bet the most genetics people probably know that, but I don't know what
 the number is. Okay. Let's see. I see work like this as the latest in a series of arguments against
 the dualist project. If biology enables the system of minds at every level of cellular organization
 and spanning them, then shouldn't it be possible to theorize that this behaviors you describe
 and something like language or reasoning, which has been a more traditional domain for cognitive
 theory? I'm not sure I understand the second half of that. I guess I can say something about the
 dualist aspect if I understood that correctly. I mean, on the one hand, this kind of work is
 absolutely not dualist because we insist that the products of it, the theory and the experiments,
 be physically tractable. That is all of this is meant to drive experiments to interact with
 the physical world. So nobody's claiming that there's anything here that is in some way outside
 the reach of experiment. On the other hand, I take very seriously this idea that there are
 functionally important, I don't know what you would call them. We don't have the vocabulary
 for it, but functionally important patterns that are not physical in the sense that you do not
 find them in the physical world. I think evolution uses them extensively, things like the truths of
 number theory, for example, that would still be exactly the same if the laws of physics were
 different in this universe. So I think evolution uses the laws of computation, the laws of mathematics
 extensively and those things, you can think of it as a partially a dualist project because I think
 those exist. I do not think they're entirely reducible to physical events. And I think they
 are functionally important in driving what happens both on the evolutionary scale and on the
 developmental scale. So I don't know if that makes this model properly dualistic or not.
 Let's have some questions from the panel here. Gary.
 Yeah. See how I can articulate this. So one constant in the kind of biological work that
 you were describing is that the systems are self-replicating. So they have to work within
 the constraints of genetics, of biology, in addition to whatever aspects of computation,
 of mathematics, evolution has stumbled on. And if we think about applying, so there's a clear
 path for applying what we're learning from those kinds of studies to other aspects of
 biology in some of the examples you used. But in thinking about intelligence more generally,
 and for example, so artificial intelligence, it's kind of interesting to try to draw a line
 to human ventures into trying to invent new kinds of intelligence, where on the one hand,
 artificial systems that we invent are not self-replicating systems. They're
 sort of in one sense outside of biology. In another sense, they are part of biology
 in an extended sense in that we as biological creatures came up with them.
 But that said, a digital computer is a qualitatively different kind of system than a biological
 computer with different material properties, different operating principles and under a very
 different set of limitations and constraints. So the question is, how do you think about the
 opportunities to learn about kinds of intelligence, including artificial intelligence from the
 study of biological systems that are under these sort of different sets of constraints?
 So one might think that freed from the constraints of biology,
 the constraints of biology are a kind of limitation and that by trying to play within those rules,
 we limit ourselves to a certain set of solutions. On the other hand, of course, one would say,
 well, evolution is a lot smarter than you are. It's figured things out over a much longer
 time scale and the amount that we can learn from those solutions far outstrips any kind of
 limitations that come from the system operating within those constraints.
 I hope that made some sense.
 Yeah, definitely.
 Maybe I can chime in and say what you call constraints might actually also be called
 triers. And in a way, it helps when there are multiple solutions to select the one that fits
 better and evolution has selected the set of triers that is more efficient for the environment
 we're in. So not having these triers make our AI systems not doing the right things
 compared to biological systems. So sometimes they're good. That's what I'm saying.
 Yeah, I mean, a lot of interesting things there. One is you're absolutely right in that not only
 did we make them, at least the ones we have now, but also in a certain weird sense, we are their
 embodiment because we change massive amounts of effort, money, energy, climate, this stuff,
 moves around depending on what these things do or do not do. So in a certain sense, we are part of
 the embodiment for a lot of these things. And overall, big picture, I don't believe that
 evolution has any monopoly on producing minds. That's how it's happened so far on earth and
 that's fine, but I don't see why in principle it has to be the meanderings of a search process that
 gives rise to this and that we couldn't do it with engineering that took lessons from what we already
 see as a good positive control case. So I think if we pay attention to what the biological constraints
 have led to, I think there are some very important biological constraints. For example, the time and
 energy constraint, the fact that you don't have the time and the energy to sit around and be a
 Laplacian demon and track microstates, you'll be dead and eaten before you calculate anything.
 You have to believe in higher level agents that do things as an observer. And I'm talking about
 cells, I'm not even talking about humans, but you have to coarse grain and you have to make decisions
 about what to pay attention to and look for higher order patterns. That's just a fundamental
 requirement of remaining alive in the living world. That aspect of it immediately puts you
 in a different category than a system that doesn't have to worry about energy and has all
 the time it needs. Now, that doesn't mean we have to use those constraints in our engineering,
 but it does mean that we have to take the lessons of them and then implement from there. And I think
 we could. Do you have anything to add? Well, I have a question. So I don't want to say class,
 because I think it implies a discrete categorization or the continuum, but there's
 the sort of part of the spectrum of the wood that you consider has an analog to the neural scaling
 laws of neural systems. So is there a sense of how does the computation scale with various factors?
 Is that a question for me? Yeah. Okay. Yeah. Great question. There are definitely some things that
 scale nicely and some things that don't. So for example, one of the things that happens is that
 with the scale of the organism, as always, messages take different times to pass because
 they have to go from cell to cell. And so what you find is that much larger systems have longer
 times between the something happening on one side of the animal and the reactions from others,
 because it is very much a distributed system. So for example, I'll just give you an idea.
 In the froglet, which is maybe 10 centimeters in size, if you cut one of the legs, the other leg
 that you didn't touch within 30 seconds, it knows about it because you can see the same voltage
 pattern in the untouched healthy leg as you see in the wound. So that takes about 30 seconds.
 So on a developmental time scale, that's extremely fast because the regrowth is going to take a year
 and a half, two years. So that's very fast. But if you track it, it takes 30 seconds for that,
 and it's way slower than neural conduction would be. So it is scaled that way. And there's even a
 proportional... If you look at the ratio between the speed of conduction in neurons versus the
 propagation through these gap junction fields versus the time scale of behavior versus the
 time scale of development, there's a reasonable scaling factor that connects those two.
 Oh, okay. Should I talk there or... Let's talk there. So I'm not a biologist. I was
 thinking of Maturana and Varela's concept of autoprietic system in biology. And I was trying
 to figure out how to formulate a narrower question, but in the end, I don't really know.
 My question would be, does this approach that focuses more on different kinds of cognition
 changes the way that you would define an autoprietic biological system? So the pattern,
 the capacity to create pattern influences the way you would define the identity of a biological
 system. And would you characterize what you're studying as example of reduction of complexity
 from the point of view of the system? It's very... That's it. Sorry.
 That's to you. It's to you.
 To me? Okay. A couple of things. Well, reduction of complexity, absolutely, because one of the
 amazing things about this biological architecture is that it drastically reduces the complexity
 and the amount of knowledge needed to control it. So for example, in the nervous system, we know
 all about this because if you have a rat and you want it to do a circus trick, if you were there
 trying to run it like a puppet controlling all the neurons, you'd be here for a really long time,
 versus you can just train the rat and you're taking advantage of the fact that it has this
 nice learning interface that handles all the internal steps needed to get from what you want
 to the behavior of the system. The stuff that we study is exactly the same. I could, in theory,
 try to go in and micromanage every cell and in fact, every gene in every cell to get these
 complicated things to happen. But what the architecture does, because that's not how the
 biology controls itself either, is we're just hacking what it normally does, which is to use
 high level stimuli to trigger it into certain behavior. So absolutely, there's a reduction of
 complexity on the control side. With respect to the autopoietic systems, I think what's really
 fundamental going all the way down is the question of the border between self and world, specifically
 with respect to who do memories belong to. I think a lot of this is about the scale of goals,
 the cognitive light cone that determines the size of the biggest goal the system can possibly care
 about. And specifically, what level do these memories belong to? Because much like, again,
 when you have a rat and he presses a lever and he gets a reward, the cells at the bottom of the feet
 interact with a lever. The cells in the gut get the delicious reward. No individual cell had both
 experiences. So when you ask who has this associative memory, it's the rat. It's the
 collective. And of course, the nervous system does a great job in binding the cells into this
 collective that it can own these memories that don't belong to any of the parts.
 And developmentally, it's exactly the same thing. When you're looking at an embryonic blastoderm,
 the question is, which cells are part of one network that has a representation of the shape
 that they're trying to build? And where's the best place to draw a boundary for us as an observer?
 Now, the next question is where does the system itself draw that boundary internally? But that's
 what I think it's about. I think it's about drawing boundaries that own goals and memories
 in whatever your implementation. There is a question on chat from Daniel.
 Societal systems, when looked at a distance, can be described as having intelligent agency,
 adaptive problem solving, but don't have a unified sentient experience, but I do. What causes the
 difference between one type of system, a city, and the other, me, and how can we tell them apart?
 And I think, Mike, you and I probably agree that the sense of unified agency in people is often
 not quite true and can be demonstrated to often not be there. Nevertheless, I think
 what Daniel is getting at is that there is a sense in which an animal is a more unified
 kind of intelligence than a city. So, I don't know, do you think there is some principled
 way, given the system, to know how unified the intelligence is? And obviously, yeah, open to
 everyone. I mean, in terms of unified, there are definitely mathematical tools to gauge that. So,
 like Tononi's integrated information theory and things like that, people have developed
 some math around trying to quantify how unified and irreducible something is. So, that does exist,
 whether that measures conscious experience or not, I'm not sure, but at least you can quantify
 how unified it is. With respect to intelligence, again, I don't know the data on societies and
 cities, but you would really have to do very behavioral type of experiments where you would
 have to show that there are goal states and that if you deviate them, they can come back and they
 can go around obstacles and maybe they have associative learning and maybe they have planning
 and maybe they don't. I'm not aware of that data, so I actually don't know. But let's assume for
 the moment, just for the sake of argument, that those data existed and that you could say that,
 wow, yes, indeed, societies solve problems and have goals on the scale of, I don't know,
 a cat or something. I don't see why that wouldn't be possible, but let's just say for a moment that
 data existed, then I think it would be really presumptuous to have as the assumption that,
 well, we have a centralized consciousness or an inner perspective and they don't. I'm not sure how
 you could possibly say that. I don't believe that we have a good understanding of which kinds of
 materials and which kind of architectures support it other than the examples, the sort of N equals
 one examples that we have here on Earth. I don't see why you would say it. I don't know how we can
 know that. Is there a set of questions that need to be asked to verify that I could ask the city
 and to you? For me, what I think is really important, and again, I think it's a spectrum,
 not a fine line, but I think what's important is to what extent do you need to consider the
 system's inner perspective to have an efficient relationship with it? For example, if you have a
 landscape with a bunch of hills and valleys, you have a bowling ball, you're, as a third-person
 observer, your view of the landscape is all you need. That tells you everything you need to know.
 But if you have a mouse on that landscape, your view of the landscape is kind of irrelevant.
 What matters is how does the mouse view this landscape? You're not going to get far with
 Newton's laws with a mouse. For example, in regenerative biology, I think we face exactly
 this problem that you, as the bioengineer, has a view of what's going on, but what's actually
 important is what do the cells believe? Literally, what are their priors? What are their set points
 for stress and for risk and things like that? It's very important. I think to the extent that,
 and I certainly don't have a new theory of consciousness to float out here yet, but in
 terms of inner perspective, I think that to the extent that taking the perspective of the system
 is important in being able to have an effective relationship with it, I think to that extent,
 it has an inner perspective. You would just do the same experiments with the city. Functionally,
 it would be expensive and probably unethical, but you could do those kinds of experiments.
 For example, somebody said to me once, "Well, on this kind of crazy view, probably you'll say
 the weather is agentic." Well, I don't know, but it's not impossible that somebody figures out that
 hurricane weather patterns can have habituation or if you have the right way of stimulating,
 who knows? These are empirical questions. You would have to try it and see.
 This seems like the intentional stance. There's a lot of value of taking the intentional
 stance to study a system. For example, reframing that question about the experiences of a city,
 one might think, "Okay, if what you want to do is change some aspect of a city's health,
 whether that's traffic flow or spread of disease or happiness of the inhabitants."
 Even if it's the individual people who are having experiences, you need to take the
 perspective of the collective city because studying the individuals is just not the right
 perspective because the relevant information is in the whole. It doesn't mean it's completely
 irreducible. There's a literature on situated cognition that does this. Ed Hutchins is one
 person that did a lot of work on it studying, for example, aircraft carriers as systems where
 you have this distributed cognition, but it's situated in that the relevant behaviors that
 you get from people are always in the context of a particular system. It doesn't do you much good
 to look at a person as an individual agent in that context and say, "What do they know?
 What are they doing?" Because what they know and what they're doing is in the context of
 a particular system, and one has to take this perspective of the system. I don't know what's
 further gained by talking about the experiences of the aircraft carrier itself, but no.
 [inaudible]
 Yeah, that's it.
 [inaudible]
 Yeah. Daniel, "Other than Darwinist evolution working within the known laws of physics,
 is there any other source for the complex order we see?" First thing that comes to mind is cultural
 evolution. It's Darwinian in some ways, non-Darwinian in others, but that does a whole lot.
 This is an answer to what?
 That goes to questions.
 The question other than Darwinist evolution.
 Oh, okay. Have you looked at the ones that came in? What's the last one that you have?
 From Julia [inaudible]
 Okay, so I think that's it.
 Okay, so I'll just use executive privilege again. I just want to say something to
 Mike as a vegan myself. My criterion is life, death, necessity, and your research meets it.
 Even for a vegan, a lion is allowed to eat an antelope, because otherwise they die. When it
 comes to fighting diseases, it would be immoral not to try. So I don't think there's any conflict
 there. Thank you for everything. We'll do one last applause for you, for all of you.
 No, you don't applaud because you're being applauded.
 Thank you so much, everyone.
 We'll see you tomorrow.
